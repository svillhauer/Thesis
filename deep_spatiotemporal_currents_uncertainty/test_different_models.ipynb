{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Project Imports ---\n",
    "from src.data.cmems_dataset import load_cmems_uv, SlidingWindowUVDataset\n",
    "from src.utils import seed_all\n",
    "\n",
    "# --- Configuration ---\n",
    "CONFIG = {\n",
    "    \"data_path\": \"/home/svillhauer/Desktop/Thesis/Currents/deep_spatiotemporal_currents/src/data/cmems_mod_glo_phy_anfc_merged-uv_PT1H-i_1770985217793.nc\", \n",
    "    \"out_dir\": \"thesis_experiments\",\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-3,\n",
    "    \"seq_len\": 3,\n",
    "    \"base_ch\": 32,\n",
    "    \"lstm_ch\": 128,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "seed_all(CONFIG['seed'])\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {DEVICE}\")\n",
    "os.makedirs(CONFIG['out_dir'], exist_ok=True)\n",
    "\n",
    "# --- Z-Score Helper Classes (Defined Here to Ensure Consistency) ---\n",
    "class ZScoreStats:\n",
    "    def __init__(self, u_mean, u_std, v_mean, v_std):\n",
    "        self.u_mean = u_mean\n",
    "        self.u_std = u_std\n",
    "        self.v_mean = v_mean\n",
    "        self.v_std = v_std\n",
    "\n",
    "def compute_zscore(uv):\n",
    "    # uv: (T,2,H,W)\n",
    "    u = uv[:,0]\n",
    "    v = uv[:,1]\n",
    "    \n",
    "    u_mean = np.mean(u)\n",
    "    u_std  = np.std(u) + 1e-8\n",
    "    v_mean = np.mean(v)\n",
    "    v_std  = np.std(v) + 1e-8\n",
    "    \n",
    "    return ZScoreStats(u_mean, u_std, v_mean, v_std)\n",
    "\n",
    "def apply_zscore(uv, stats):\n",
    "    uv_n = uv.copy()\n",
    "    uv_n[:,0] = (uv_n[:,0] - stats.u_mean) / stats.u_std\n",
    "    uv_n[:,1] = (uv_n[:,1] - stats.v_mean) / stats.v_std\n",
    "    return uv_n\n",
    "\n",
    "def invert_zscore(uv_n, stats):\n",
    "    \"\"\"Converts normalized data back to physical units (m/s)\"\"\"\n",
    "    # Handle both tensor and numpy input\n",
    "    if isinstance(uv_n, torch.Tensor):\n",
    "        uv_n = uv_n.detach().cpu().numpy()\n",
    "        \n",
    "    uv = uv_n.copy()\n",
    "    uv[:,0] = uv[:,0] * stats.u_std + stats.u_mean\n",
    "    uv[:,1] = uv[:,1] * stats.v_std + stats.v_mean\n",
    "    return uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. ConvLSTM Cell ---\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        \n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        \n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=DEVICE),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=DEVICE))\n",
    "\n",
    "# --- 2. Thesis Variant Model ---\n",
    "class ThesisVariant(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, base_ch=32, lstm_ch=128, seq_len=3, mode='unet_convlstm'):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        def double_conv(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, 1, 1), nn.BatchNorm2d(out_c), nn.ReLU(True),\n",
    "                nn.Conv2d(out_c, out_c, 3, 1, 1), nn.BatchNorm2d(out_c), nn.ReLU(True)\n",
    "            )\n",
    "        \n",
    "        self.inc = double_conv(in_ch, base_ch)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), double_conv(base_ch, base_ch * 2))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), double_conv(base_ch * 2, base_ch * 4))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), double_conv(base_ch * 4, base_ch * 8))\n",
    "\n",
    "        if 'lstm' in mode:\n",
    "            self.bottleneck = ConvLSTMCell(base_ch * 8, lstm_ch, (3,3), True)\n",
    "            bot_out_ch = lstm_ch\n",
    "        else:\n",
    "            self.bottleneck = double_conv(base_ch * 8, lstm_ch)\n",
    "            bot_out_ch = lstm_ch\n",
    "\n",
    "        use_skips = ('unet' in mode)\n",
    "        self.up1 = UpBlock(bot_out_ch, base_ch * 4, use_skips)\n",
    "        self.up2 = UpBlock(base_ch * 4, base_ch * 2, use_skips)\n",
    "        self.up3 = UpBlock(base_ch * 2, base_ch, use_skips)\n",
    "        self.outc = nn.Conv2d(base_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if 'lstm' in self.mode:\n",
    "            b, t, c, h, w = x.shape\n",
    "            x_flat = x.view(b * t, c, h, w)\n",
    "            x1 = self.inc(x_flat)\n",
    "            x2 = self.down1(x1)\n",
    "            x3 = self.down2(x2)\n",
    "            x4 = self.down3(x3) \n",
    "            \n",
    "            lstm_in = x4.view(b, t, -1, x4.shape[-2], x4.shape[-1])\n",
    "            h_state, c_state = self.bottleneck.init_hidden(b, (x4.shape[-2], x4.shape[-1]))\n",
    "            for t_step in range(t):\n",
    "                h_state, c_state = self.bottleneck(lstm_in[:, t_step], (h_state, c_state))\n",
    "            bot_out = h_state\n",
    "            \n",
    "            s1 = x1.view(b, t, -1, h, w)[:, -1]\n",
    "            s2 = x2.view(b, t, -1, h//2, w//2)[:, -1]\n",
    "            s3 = x3.view(b, t, -1, h//4, w//4)[:, -1]\n",
    "            \n",
    "        else:\n",
    "            x1 = self.inc(x)\n",
    "            x2 = self.down1(x1)\n",
    "            x3 = self.down2(x2)\n",
    "            x4 = self.down3(x3)\n",
    "            bot_out = self.bottleneck(x4)\n",
    "            s1, s2, s3 = x1, x2, x3\n",
    "\n",
    "        x = self.up1(bot_out, s3)\n",
    "        x = self.up2(x, s2)\n",
    "        x = self.up3(x, s1)\n",
    "        return self.outc(x)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, use_skips):\n",
    "        super().__init__()\n",
    "        self.use_skips = use_skips\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c + (out_c if use_skips else 0), out_c, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(True),\n",
    "            nn.Conv2d(out_c, out_c, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_c), nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        if self.use_skips:\n",
    "            diffY = x2.size()[2] - x1.size()[2]\n",
    "            diffX = x2.size()[3] - x1.size()[3]\n",
    "            x1 = nn.functional.pad(x1, [diffX//2, diffX-diffX//2, diffY//2, diffY-diffY//2])\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_loss(pred_mean, pred_logvar, target):\n",
    "    sq_diff = (pred_mean - target)**2\n",
    "    loss = 0.5 * torch.exp(-pred_logvar) * sq_diff + 0.5 * pred_logvar\n",
    "    return loss.mean()\n",
    "\n",
    "def train_and_evaluate(mode, train_loader, val_loader, stats, config):\n",
    "    print(f\"\\n[{mode.upper()}] Starting Training...\")\n",
    "    \n",
    "    in_ch = 2 * config['seq_len'] if mode == \"standard_unet\" else 2\n",
    "    \n",
    "    model = ThesisVariant(\n",
    "        in_ch=in_ch, out_ch=4, \n",
    "        base_ch=config['base_ch'], lstm_ch=config['lstm_ch'], \n",
    "        seq_len=config['seq_len'], mode=mode\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Pbar (optional, can remove if too noisy)\n",
    "        pbar = tqdm(train_loader, desc=f\"Ep {epoch}\", leave=False)\n",
    "        for X, Y in pbar:\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            \n",
    "            if mode == \"standard_unet\":\n",
    "                b, t, c, h, w = X.shape\n",
    "                X = X.view(b, t * c, h, w)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            pred_mean, pred_logvar = out[:, :2], out[:, 2:]\n",
    "            \n",
    "            loss = uncertainty_loss(pred_mean, pred_logvar, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            \n",
    "        # Validation\n",
    "        val_rmse, val_nll = evaluate(model, val_loader, stats, mode)\n",
    "        \n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"val_rmse\": val_rmse,\n",
    "            \"val_nll\": val_nll,\n",
    "            \"train_loss\": total_loss / len(train_loader)\n",
    "        })\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Ep {epoch}: Train Loss={total_loss/len(train_loader):.3f} | Val RMSE={val_rmse:.3f} | Val NLL={val_nll:.3f}\")\n",
    "            \n",
    "    return history, model\n",
    "\n",
    "def evaluate(model, loader, stats, mode):\n",
    "    model.eval()\n",
    "    rmse_accum = 0\n",
    "    nll_accum = 0\n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            if mode == \"standard_unet\":\n",
    "                b, t, c, h, w = X.shape\n",
    "                X = X.view(b, t * c, h, w)\n",
    "                \n",
    "            out = model(X)\n",
    "            pred_mean, pred_logvar = out[:, :2], out[:, 2:]\n",
    "            \n",
    "            # NLL (Loss in normalized space)\n",
    "            loss = uncertainty_loss(pred_mean, pred_logvar, Y)\n",
    "            nll_accum += loss.item() * X.size(0)\n",
    "            \n",
    "            # RMSE (Physical Units - Z-Score Inversion)\n",
    "            # 1. Invert Prediction\n",
    "            pred_phys = invert_zscore(pred_mean, stats)\n",
    "            # 2. Invert Ground Truth\n",
    "            true_phys = invert_zscore(Y, stats)\n",
    "            \n",
    "            # 3. Calculate Speed RMSE\n",
    "            sq_err = (pred_phys - true_phys)**2\n",
    "            rmse_accum += np.sqrt(np.mean(sq_err)) * X.size(0)\n",
    "            count += X.size(0)\n",
    "            \n",
    "    return rmse_accum / count, nll_accum / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Data Shape: (1045, 2, 64, 64) (Time, Channels, H, W)\n",
      "Computing Z-Score Stats on Train set...\n",
      "  U mean=0.1161, std=0.1591\n",
      "  V mean=-0.0443, std=0.1502\n",
      "\n",
      "[UNET_CONVLSTM] Starting Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 111\u001b[0m\n\u001b[1;32m    108\u001b[0m MODES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munet_convlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_convlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard_unet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m MODES:\n\u001b[0;32m--> 111\u001b[0m     hist, trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     results[mode] \u001b[38;5;241m=\u001b[39m hist\n\u001b[1;32m    115\u001b[0m     models[mode] \u001b[38;5;241m=\u001b[39m trained_model\n",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(mode, train_loader, val_loader, stats, config)\u001b[0m\n\u001b[1;32m     46\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 3. Validation\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m val_rmse, val_nll \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m history\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch,\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_rmse,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_nll\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_nll,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     56\u001b[0m })\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[12], line 95\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, loader, stats, mode)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# RMSE (Physical Units - using Z-Score Inversion)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m pred_phys \u001b[38;5;241m=\u001b[39m invert_zscore(pred_mean\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), stats)\n\u001b[0;32m---> 95\u001b[0m true_phys \u001b[38;5;241m=\u001b[39m \u001b[43minvert_zscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Calculate RMSE on magnitude (speed) or vector distance\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Here we use vector distance: sqrt((u-u')^2 + (v-v')^2)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m sq_err \u001b[38;5;241m=\u001b[39m (pred_phys \u001b[38;5;241m-\u001b[39m true_phys)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m, in \u001b[0;36minvert_zscore\u001b[0;34m(uv_n, stats)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvert_zscore\u001b[39m(uv_n, stats):\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts normalized data back to physical units (m/s)\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     uv \u001b[38;5;241m=\u001b[39m \u001b[43muv_n\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     uv[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m uv[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m stats\u001b[38;5;241m.\u001b[39mu_std \u001b[38;5;241m+\u001b[39m stats\u001b[38;5;241m.\u001b[39mu_mean\n\u001b[1;32m     44\u001b[0m     uv[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m uv[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m stats\u001b[38;5;241m.\u001b[39mv_std \u001b[38;5;241m+\u001b[39m stats\u001b[38;5;241m.\u001b[39mv_mean\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Learning Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "labels = {\n",
    "    \"unet_convlstm\": \"Proposed (U-Net + LSTM)\",\n",
    "    \"cnn_convlstm\": \"No Skips (CNN + LSTM)\",\n",
    "    \"standard_unet\": \"No Memory (Standard U-Net)\"\n",
    "}\n",
    "\n",
    "for mode in MODES:\n",
    "    if mode in results and len(results[mode]) > 0:\n",
    "        df = pd.DataFrame(results[mode])\n",
    "        plt.plot(df['epoch'], df['val_rmse'], label=labels[mode], marker='.')\n",
    "\n",
    "plt.title(\"Thesis Model Comparison: RMSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE (m/s)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 2. Difference Field (Qualitative)\n",
    "sample_idx = 10 \n",
    "X_sample, Y_sample = val_ds[sample_idx]\n",
    "\n",
    "# Ensure inputs are Tensors\n",
    "if isinstance(X_sample, np.ndarray):\n",
    "    X_in = torch.from_numpy(X_sample).float().unsqueeze(0).to(DEVICE)\n",
    "else:\n",
    "    X_in = X_sample.float().unsqueeze(0).to(DEVICE)\n",
    "\n",
    "# Get Ground Truth Speed (Use invert_zscore)\n",
    "if isinstance(Y_sample, torch.Tensor):\n",
    "    Y_sample_np = Y_sample.cpu().numpy()\n",
    "else:\n",
    "    Y_sample_np = Y_sample\n",
    "\n",
    "# FIX: Using invert_zscore here\n",
    "Y_phys = invert_zscore(Y_sample_np, stats)\n",
    "true_speed = np.sqrt(Y_phys[0]**2 + Y_phys[1]**2)\n",
    "\n",
    "# Setup Figure\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 8), constrained_layout=True)\n",
    "max_speed_disp = np.max(true_speed)\n",
    "max_error_disp = max_speed_disp * 0.5 \n",
    "\n",
    "# Plot Ground Truth\n",
    "im_gt = axes[0,0].imshow(true_speed, cmap='viridis', vmin=0, vmax=max_speed_disp)\n",
    "axes[0,0].set_title(\"Ground Truth\\n(Current Speed)\")\n",
    "axes[0,0].axis('off')\n",
    "fig.colorbar(im_gt, ax=axes[0,0], fraction=0.046, pad=0.04, label=\"m/s\")\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "for i, mode in enumerate(MODES):\n",
    "    if mode not in models: continue\n",
    "    model = models[mode]\n",
    "    model.eval()\n",
    "    \n",
    "    if mode == \"standard_unet\":\n",
    "        inp = X_in.view(1, -1, X_in.shape[-2], X_in.shape[-1])\n",
    "    else:\n",
    "        inp = X_in\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        out = model(inp)\n",
    "    \n",
    "    # FIX: Using invert_zscore here\n",
    "    pred_phys = invert_zscore(out[0, :2].cpu().numpy(), stats)\n",
    "    pred_speed = np.sqrt(pred_phys[0]**2 + pred_phys[1]**2)\n",
    "    diff = np.abs(true_speed - pred_speed)\n",
    "    \n",
    "    # Plot Prediction\n",
    "    im_pred = axes[0, i+1].imshow(pred_speed, cmap='viridis', vmin=0, vmax=max_speed_disp)\n",
    "    axes[0, i+1].set_title(f\"{labels[mode]}\\nPrediction\")\n",
    "    axes[0, i+1].axis('off')\n",
    "    \n",
    "    # Plot Difference\n",
    "    im_err = axes[1, i+1].imshow(diff, cmap='inferno', vmin=0, vmax=max_error_disp)\n",
    "    axes[1, i+1].set_title(f\"Error Difference\\n{labels[mode]}\")\n",
    "    axes[1, i+1].axis('off')\n",
    "    cb = fig.colorbar(im_err, ax=axes[1, i+1], fraction=0.046, pad=0.04)\n",
    "    cb.set_label(\"Error (m/s)\")\n",
    "\n",
    "plt.suptitle(f\"Comparison at Sample {sample_idx}\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Learning Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "labels = {\n",
    "    \"unet_convlstm\": \"Proposed (U-Net + LSTM)\",\n",
    "    \"cnn_convlstm\": \"No Skips (CNN + LSTM)\",\n",
    "    \"standard_unet\": \"No Memory (Standard U-Net)\"\n",
    "}\n",
    "\n",
    "for mode in MODES:\n",
    "    df = pd.DataFrame(results[mode])\n",
    "    plt.plot(df['epoch'], df['val_rmse'], label=labels[mode], marker='.')\n",
    "\n",
    "plt.title(\"Thesis Model Comparison: RMSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE (m/s)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 2. Difference Field (Qualitative)\n",
    "# Pick a specific sample to visualize\n",
    "sample_idx = 10 \n",
    "X_sample, Y_sample = val_ds[sample_idx]\n",
    "X_in = torch.tensor(X_sample).unsqueeze(0).to(DEVICE) # (1, T, 2, H, W)\n",
    "\n",
    "# Get Ground Truth Speed\n",
    "Y_phys = invert_minmax(Y_sample, stats)\n",
    "true_speed = np.sqrt(Y_phys[0]**2 + Y_phys[1]**2)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Plot GT\n",
    "axes[0,0].imshow(true_speed, cmap='viridis')\n",
    "axes[0,0].set_title(\"Ground Truth\")\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "for i, mode in enumerate(MODES):\n",
    "    model = models[mode]\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare input\n",
    "    if mode == \"standard_unet\":\n",
    "        inp = X_in.view(1, -1, X_in.shape[-2], X_in.shape[-1])\n",
    "    else:\n",
    "        inp = X_in\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        out = model(inp)\n",
    "    \n",
    "    # Phys conversion\n",
    "    pred_phys = invert_minmax(out[0, :2].cpu().numpy(), stats)\n",
    "    pred_speed = np.sqrt(pred_phys[0]**2 + pred_phys[1]**2)\n",
    "    diff = np.abs(true_speed - pred_speed)\n",
    "    \n",
    "    # Plot Pred\n",
    "    axes[0, i+1].imshow(pred_speed, cmap='viridis')\n",
    "    axes[0, i+1].set_title(labels[mode])\n",
    "    \n",
    "    # Plot Diff\n",
    "    axes[1, i+1].imshow(diff, cmap='inferno')\n",
    "    axes[1, i+1].set_title(f\"Error ({mode})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
